\documentclass[10pt]{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{kpfonts}
\usepackage[left=2.8cm, right=2.8cm, top=2.8cm, bottom=3cm]{geometry}
\usepackage{titling}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}

\graphicspath{{ims/}}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}

%%%%%%%%%%%% Title Part %%%%%%%%%%%%
\pretitle{
	\begin{center}
	\includegraphics[width=4cm]{logo_ens_lyon.pdf}
	\hspace{5cm}
	\includegraphics[width=5.5cm]{logo_tu_delft.png}
	\LARGE
}
\title{
	\rule{\linewidth}{0.4mm}
	\textbf{Perspective Check in Paintings} \\
	\textit{M1 Internship}
	\rule{\linewidth}{0.6mm}
}
\author{
	Yoann Coudert--Osmont \\[3mm]
	\textit{Supervised by} \\
	Elmar Eisemann \qquad Ricardo Marroqium \\[2mm]
}
\date{May - July 2019}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
	\maketitle
	
	\section*{Introduction}
	
	\begin{figure}
		\centering
		\includegraphics[scale=1.25]{paintings_pair.jpg}
		\caption{A pair of similar paintings}
		\label{im:pair}
	\end{figure}

	In a Delft museum, paintings by Pieter de Hooch are on display. It is quite easy to notice that some pairs of paintings are very similar (e.g. \figurename \ref{im:pair}). One hypothesis that would explain this strangeness is the possibility that another painter copied Pieter de Hooch's paintings. Looking at the pairs in more detail, we can notice that quite often one painting respects the rules of perspective well and the other does not respect them. This gives credibility to the hypothesis of the existence of another painter. But the human tends to be biased to check that in each pair one painting respects the rules of perspective and the other does not. Then comes the need to create a tool to check whether the perspective is respected in a painting with as little human intervention as possible. The goal of this internship was therefore to create a graphical interface to verify the perspective in a painting with as much automation as possible. \\
	Tools already exist to find lines in an image. The most common and the one I used is the Hough transform \cite{hough}. I will describe the algorithms used to create my interface in this report. In most paintings there is a tiled floor and it is mainly the lines of the tiles that I studied in the paintings. The development of a graphical user interface with minimal user control was necessary because there is no guarantee that a fully automated program will do exactly what you want. Much of the internship was used to learn how to make a graphical interface with Qt and to design an interface that is easily usable. But I'm not going to describe how this interface works, I'll just give some implemented features inside this report.

	\vspace{4cm}
	\begin{center}
		\tableofcontents
	\end{center}
	
	\newpage
	
	\section{Reminders on the rules of perspective}
	
	The main rule of perspective is that when you make a drawing, the parallel lines must all cross at the same point. We call this point a vanishing point. In addition, all vanishing points must be on the same line. This line is the vanishing line and corresponds to the horizon.
	
	\begin{figure}[h]
		\centering
		\begin{tikzpicture}[thick]
			\draw[] (0, 0) -- (1, 0) -- (1, 1) -- (0, 1) -- cycle;
			\draw[red] (-2.5, 2.25) -- (6, 2.25);
			\draw[green] (0, 1) -- (0.8, 1.5);
			\draw[green, dashed] (0.8, 1.5) -- (2, 2.25);
			\draw[green] (1, 1) -- (1.4, 1.5);
			\draw[green, dashed] (1.4, 1.5) -- (2, 2.25);
			\draw (0.8, 1.5) -- (1.4, 1.5);
			\draw[green] (1, 0) -- (1.4, 0.9);
			\draw[green, dashed] (1.4, 0.9) -- (2, 2.25);
			\draw (1.4, 0.9) -- (1.4, 1.5);
			
			\node[blue] (VP) at (2, 2.25) {$\bullet$};
			\node[above, blue] at (2, 2.25) {\small Vanishing Point};
			\node[below, red] at (5, 2.25) {\small Vanishing Line};
			\node[left, green] at (0.4, 1.4) {\small Parallel lines};
		\end{tikzpicture}
		\caption{Illustration of the perspective rules}
	\end{figure}

	\subsection{Special case of a tiled floor}
	
	This subsection will be useful for the last section of this report. There are two interesting equations to record about tiled floors linking tile lines with their diagonals. Indeed I will try to build a new painting that perfectly respects the perspective. But to do this, it is necessary to know the properties that the vanishing points of a tiled floor must respect.
	
	\begin{figure}[h]
		\centering
		\begin{tikzpicture}[thick]
		\draw[very thick] (0, 6) -- (12, 6);
		\draw[semithick] (0, 0) -- (12, 0);
		\node[above] at (6, 6) {Vanishing Line};
		\node[above, red] at (0, 6) {\small $A$};
		\node[above, blue] at (4, 6) {\small $B$};
		\node[above, green] at (12, 6) {\small $C$};
		
		\foreach \i in {2, ..., 11} \draw[red] (0, 6) -- (\i, 0);
		\foreach \i in {1.333, 2.666, ..., 9.333} \draw[blue] (4, 6) -- (\i, 0);
		
		\draw[red] (2, -0.3) node {\texttt{|}} -- node[below] {$d_A$} (3, -0.3) node {\texttt{|}};
		\draw[blue] (4, -0.3) node {\texttt{|}} -- node[below] {$d_B$} (5.333, -0.3) node {\texttt{|}};
		\draw[green] (6, -0.3) node {\texttt{|}} -- node[below] {$d_C$} (8, -0.3) node {\texttt{|}};
		
		\node[below, align=center] at (10.2, 0)
			{\footnotesize line parallel to \\[-1mm]
			\footnotesize the vanishing line};
		
		\clip (0, 0) rectangle (12, 6);
		\foreach \i in {-4, -2, ..., 10} \draw[green] (12, 6) -- (\i, 0);
		\foreach \i in {4, 8, ..., 24} \draw[blue] (-12, 6) -- (\i, 0);
		\end{tikzpicture}
		\vspace{-2mm}
		\caption{Tiled floor in perspective}
		\label{im:tiledfloor}
	\end{figure}

	In the \figurename \ref{im:tiledfloor}, blue lines represent a tiled floor in perspective. We will always assume that tiles are squares. Then all the parallel lines are equally spaced. In perspective, this implies that if a line parallel to the vanishing line is drawn, then the tile lines intersect with it at regular intervals. We write these intervals $\color{blue} d_B$ for the depth lines, and $\color{red} d_A$ and $\color{green} d_C$ for the diagonals. $\color{red} A$, $\color{blue} B$ and $\color{green} C$ are the vanishing points located on the vanishing line (note that here the vanishing line is horizontal but it may not be). Finally here are the two equations respected by such a tiled floor:
	
	\begin{center}
		\begin{minipage}{0.3\linewidth}
			\begin{equation}
			{\color{blue} B} = \dfrac{{\color{green} d_C} {\color{red} A} + {\color{red} d_A} {\color{green} C}}{{\color{red} d_A} + {\color{green} d_C}}
			\end{equation}
		\end{minipage}
		\begin{minipage}{0.3\linewidth}
			\begin{equation}
			{\color{blue} d_B} = 2 \dfrac{{\color{red} d_A} {\color{green} d_C}}{{\color{red} d_A} + {\color{green} d_C}}
			\end{equation}
		\end{minipage}
	\end{center}
	
	\section{Description of the algorithm}
	
	% Need to talk about what I tried before hough transform (PCA on connex components)

	\subsection{General description}
	
	\paragraph{}
	Finding lines in an image can be broken down into several steps. For my part, I divided this task into three main steps. First I change the color space to switch from RGB space to CIE Lab space \cite{cielab}. Then I eliminate the noise and smooth the image while keeping the areas with high gradient. In the third step I calculate in each pixel of the image the direction and amplitude of the gradient. I leave some user control over the value of some thresholds used in this step. In addition, the user has the possibility to erase certain parts of the gradient that are not interesting to study perspective. Finally, the last step consists in applying the Hough transform to the gradient. The local maxima of this transformation then give us the lines contained in the image.	
	
	\subsection{Color Space}
	
	\paragraph{}
	At the beginning of my experiments I did not make any color space changes. The gradient of the image was calculated in the RGB space well known to all. In this space the colors are represented by three bytes, representing respectively the intensity of red, green and blue in the color. Unfortunately for some paintings, the amplitude of the gradient obtained did not necessarily match what I observed with the naked eye. My algorithm could return a high gradient where I could only see a slight color change and return a low gradient where I could see a boundary between two distinct colors. One of the concerns of RGB space, for example, is that it does not take into account the fact that the human eye is less sensitive to the color blue than to the color green.
	
	\paragraph{}
	The CIELAB space \cite{cielab} allows you to correct this problem. Indeed, the Euclidean distance in this space corresponds well to the difference in colour that a human observes with his eyes. It is a space more in line with human vision. The three coordinates of CIELAB represent the lightness of the color ($L^* = 0$ yields black and $L^* = 100$ indicates diffuse white), its position between red/magenta and green ($a^*$, negative values indicate green while positive values indicate magenta) and its position between yellow and blue ($b^*$, negative values indicate blue and positive values indicate yellow). Thus the difference between two colors $(L_1^*, a_1^*, b_1^*)$ and $(L_2^*, a_2^*, b_2^*)$ is given by the Euclidean distance:
	$$ \Delta E = \sqrt{(L_1^* - L_2^*)^2 + (a_1^* - a_2^*)^2 + (b_1^* - b_2^*)^2} $$
	
	\paragraph{}
	I will not give the formulas for switching from RGB to CIELAB, but I can give the intermediate steps. There is first a non-linear transformation from RBG to sRGB then a linear transformation to the XYZ space and finally a non-linear transformation from XYZ to CIELAB. Once this change of space was implemented, the results on some paints improved considerably.
	
	\subsection{Smoothing}
	
	\paragraph{}
	Smoothing is often important in image processing because it allows noise to disappear. There are many filters known to perform smoothing. There is for example the median filter which replaces each pixel by the median value on a neighbourhood, or the very used Gaussian filter which has the particularity to be applied with a low complexity thanks to a Fourrier transform. The Gaussian filter performs a weighted average of the neighboring pixels. This weighting is done using a Gaussian with a standard deviation $\sigma$. Averages are taken individually on each component of the color space. If we consider an image $I : \N \times \N \rightarrow \R$ which associates real values to integer coordinates, then applying a gaussian filter of standard deviation $\sigma$ gives the followin image $I'$:
	$$ I'(z) = \dfrac{1}{W} \sum_{z' \in \Omega_{z}} I(z') \exp \left( - \dfrac{\| z - z'\|^2}{2 \sigma^2} \right) $$
	Where $\Omega_{z}$ is a window around $z \in \N^2$ and $W = \sum_{z' \in \Omega_{z}} \exp \left( - \frac{\| z - z'\|^2}{2 \sigma^2} \right)$ is a factor of normalization. Since it is a convolution product, this can be computed in the Fourier space with a pointwise product. That's the big advantage of this filter. The problem is that it could erase borders that would be useful for finding the lines in the image.
	
	\paragraph{}
	One solution to overcome these important edge disappearances is to use a bilateral filter \cite{bil}. This filter is defined using two functions $f: \N^2 \times \N^2 \rightarrow \R$ and $g: \R \times \R \rightarrow \R$ and gives the following image:
	$$ I'(z) = \dfrac{1}{W} \sum_{z' \in \Omega_{z}} I(z) \, f(z, z') \, g \left( I(z), I(z') \right) $$
	Where $\Omega_{z}$ is still a window around $z$ and $W = \sum_{z' \in \Omega_{z}} f(z, z') g(I(z), I(z'))$. Thanks to the $g$ function, not only the position of the other pixels is taken into account, but also the value of these pixels. The idea we can then have is to use this $g$ function to ignore pixels that have a too different color in order not to smooth the borders between two different colors. Taking two Gaussian functions for f and g is then common practice and that is the choice I made:
	$$ f(z, z') = \exp \left( - \dfrac{\| z - z'\|^2}{2 \sigma_f^2} \right) \qquad g(u, u') = \exp \left( - \dfrac{\| u - u'\|^2}{2 \sigma_g^2} \right) $$
	
	\begin{figure}[h]
		\centering
		\begin{tikzpicture}
			\node at (0, 0.9) {\includegraphics[width=10cm]{smoothing.jpg}};
			\node[below] at (0, 0) {Gaussian filter};
			\node[below] at (-3.45, 0) {Original image};
			\node[below] at (3.45, 0) {Bilateral filter};
		\end{tikzpicture}
		\vspace{-2mm}
		\caption{Comparison of smoothing filters}
		\label{im:smooths}
	\end{figure}
	\vspace{-2mm}

	\paragraph{}
	It can be seen in the \figurename \ref{im:smooths} that the bilateral filter keeps the edges clean between the tiles and that the noise inside the tiles is erased. This filter therefore does exactly what we want it to do, unlike the Gaussian filter which smoothes the edges between the tiles and therefore makes it difficult to accurately locate the edges. On the other hand because of the function $g$, the filter is not a convolution product and it is therefore no longer possible to go through the Fourier transform in order to calculate the results in a fast way. That's the only downside of this filter. To compensate for this calculation time which can be long and even to simplify the steps that will follow, I leave the user the possibility to select with a lasso the interesting area to study in the painting (\figurename \ref{im:cut}).
	
	\begin{figure}[h]
		\centering
		\begin{tikzpicture}
		\node (a) at (-4, 0) {\includegraphics[scale=0.85]{zone_select.png}};
		\node (b) at (3, 0) {\includegraphics[scale=1]{bilateral.png}};
		\draw[->, ultra thick] (a) -- node[above, align=center]
			{\footnotesize Cut the image \\[-1mm]
				\footnotesize and apply \\[-1mm]
				\footnotesize bilateral filter} (b);
		\end{tikzpicture}
		\vspace{-2mm}
		\caption{The user has the possibility to select the interesting zone.}
		\label{im:cut}
	\end{figure}
	
	\subsection{Gradient}
	
	\paragraph{}
	To compute the gradient of the image, I used a Sobel filter of size $3$ by $3$. This filter calculates the amplitude of the gradient along the x-axis and the y-axis and then deduces the gradient norm and direction from it. This is done for each $C$ component of the CIELAB space. I denote by $\ast$ the convolution product. We then have:
	$$ G_{C, x} = \begin{bmatrix} -3 & 0 & 3 \\ -10 & 0 & 10 \\ -3 & 0 & 3 \end{bmatrix} \ast C
		\qquad G_{C, y} = \begin{bmatrix} -3 & -10 & -3 \\ 0 & 0 & 0 \\ 3 & 10 & 3 \end{bmatrix} \ast C
	$$
	Where $G_{C, x}$ and $G_{C, y}$ are are respectively the discrete horizontal and vertical gradients of the component $C$. We can then compute the norm of the gradient in this component:
	$$ G_C = \sqrt{G_{C, x}^2 + G_{C, y}^2} $$
	As only the direction of the gradient and not the orientation of the gradient interests us, we want to calculate the angle of the gradient modulo $\pi$ instead of $2 \pi$. We then defines $(G_{C, x}', \, G_{C, y}')$ equal to $(G_{C, x}, \, G_{C, y})$ if $G_{C, x} \geqslant 0$ or to $(-G_{C, x}, \, -G_{C, y})$ otherwise. Finally, the norm $G$ and the angle $\theta$ of the gradient are obtained as follows:
	$$ G = \sqrt{G_{L^*} + G_{a^*} + G_{b^*}} \qquad \theta = \arg \left( G_{L^*} G_{L^*, x}' + G_{a^*} G_{a^*, x}' + G_{b^*} G_{b^*, x}' + i \left( G_{L^*} G_{L^*, y}' + G_{a^*} G_{a^*, y}' + G_{b^*} G_{b^*, y}' \right) \right)$$
	
	\begin{figure}[h]
		\centering
		\begin{tikzpicture}
		\node at (0, 0) {\includegraphics[scale=1.125]{bilateral2.png}};
		\node at (8.15, 0) {\includegraphics[scale=1.125]{sobel0.png}};
		\end{tikzpicture}
		\vspace{-5mm}
		\caption{Result of the Sobel filter}
		\label{im:sob}
	\end{figure}
	\vspace{-2mm}

	\paragraph{}
	The \figurename \ref{im:sob} we can see the result obtain on the same painting used in the previous part about smoothing (I will use this painting throughout the explanation of the algorithm). The image on the left is the smoothed paint from the previous part and the one on the right is the image representing the gradient. For each pixel, the intensity of the color represents the norm of the gradient. In the image I give, the intensity is proportional to the square root of the norm. This choice was made so that it could be seen that despite the smoothing done previously, the gradient norm is not zero inside the tiles. The color gives the angle of the gradient. Red for $0+\Z \pi$, green for $\pi / 3 + \Z \pi$ and blue for $2\pi / 3 + \Z \pi$.
	
	\paragraph{Automatic cleaning}
	To eliminate the remaining noise and make the rest easier, I clean the image a little bit. To do so, I apply a threshold that will zero all pixels in the gradient whose intensity is less than a certain value. Then I calculate the connected components of the remaining pixels and zero all pixels of the connected components that have a size smaller than a minimum size. I have a function that calculates the intensity threshold and minimum size of the related components based on the characteristics of the image. Unfortunately, these two values are not always perfect. I therefore allow the user to modify these values if necessary using sliders. The effect of this cleaning is illustrated in \figurename \ref{im:clean}.
	
	\begin{figure}
		\centering
		\begin{tikzpicture}
		\node (a) at (0, 0) {\includegraphics[scale=2.4]{sobel_wc.png}};
		\node (b) at (6, 0) {\includegraphics[scale=2.4]{sobel_c.png}};
		\draw[->, ultra thick] (a) -- node[above] {\small Cleaning} (b);
		\node (c) at (5.5, -1.72) {\scriptsize Erased because connected component too small};
		\draw[->, thick, gray] (c.west) -- (0.85, -0.29);
		\node (d) at (-0.15, -1.6) {\scriptsize Erased because the intensity is too low};
		\draw[->, thick, gray] (d.north) -- (-0.75, -0.45);
		\end{tikzpicture}
		\vspace{-2mm}
		\caption{Cleaning the gradient image}
		\label{im:clean}
	\end{figure}

	\paragraph{Smoothing}
	It can be noted that the direction of the gradient is not perfect. Some isolated pixels, or even groups of pixels, do not have a good direction. However, in the following I will use this direction to find the lines. That's why I smooth the direction in the gradient image. This is the function that gives the new smoothed value of a pixel of the gradient:
	
	\begin{algorithm}
		\caption{Gradient Smoothing}
		\label{alg:magn}
		\begin{algorithmic}
			\State $M \gets \begin{bmatrix}
				0.0925 & 0.12 & 0.0925 \\
				0.12 & 0.15 & 0.12 \\
				0.0925 & 0.12 & 0.0925
			\end{bmatrix}$
			\Function{SmoothGrad}{$G, \theta, x, y$}
			\State $a, b \gets 0, 0$
			\For{$i, j \in \{ -1, 0, 1 \}^2$}
				\State $a \gets a + M[j+1][i+1] \times G[x+i][y+j] \times \cos \left( 2 \times \theta[x+i][y+j] \right)$
				\State $b \gets b + M[j+1][i+1] \times G[x+i][y+j] \times \sin \left( 2 \times \theta[x+i][y+j] \right)$
			\EndFor
			\State $\theta[x][y] \gets \arg \left( a + ib \right) \, / \, 2$
			\EndFunction
		\end{algorithmic}
	\end{algorithm}

	The function calculates a weighted average in a neighborhood of size $3 \times 3$. The weight depends on the distance (thanks to the $M$ matrix) and the amplitude of the gradient. In addition, the factor 2 that appears in the cosine and sinus comes from the fact that we consider angles modulo $\pi$. Finally, because a single step of this smoothing is not enough, this algorithm is called several times. For example, for the paint that we use as an example, we apply 5 times the smoothing. For higher resolution images (because this one is low resolution), I can apply up to 15 smoothing steps for the gradient.
	
	\subsection{Hough Transform}
	
	\begin{figure}[h]
		\centering
		\includegraphics[scale=1.2]{hough_painting.png}
		\caption{Hough Transform}
	\end{figure}

	\section{Attempt to redraw the paintings with a perfect perspective}

	\section{Conclusion}
	
	As a conclusion I did nothing during this internship !
	
	\appendix
	
	\section{Source Code}
	
	Here is my git repository: \url{https://github.com/Nanored4498/Painting-Analysis}.

	\bibliographystyle{alpha}
	\bibliography{bib.bib}
	
\end{document}